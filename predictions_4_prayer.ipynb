{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8b0c5a",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cd383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.prediction_engine import get_final_data\n",
    "# final_data = get_final_data(save_to_csv=False)\n",
    "final_data = pd.read_csv('data/final_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521433d",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e90602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothychung/Documents/FYP Code/.venv/lib/python3.12/site-packages/torch/__init__.py:1240: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:436.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorly as tl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model.prediction_engine import PredictionTestEngine\n",
    "\n",
    "final_data = final_data.sort_values(['year_month', 'GVKEY'])\n",
    "final_data['trt1m'] = pd.to_numeric(final_data['trt1m'], errors='coerce')\n",
    "\n",
    "# feature columns\n",
    "feature_cols = [c for c in final_data.columns \n",
    "                if c not in ['GVKEY','year_month','trt1m']]\n",
    "for col in feature_cols:\n",
    "    final_data[col] = pd.to_numeric(final_data[col], errors='coerce')\n",
    "\n",
    "# Build Y (T × n_series)\n",
    "Y_df = (final_data\n",
    "    .pivot_table(index='year_month', columns='GVKEY', \n",
    "                 values='trt1m', aggfunc='mean')\n",
    "    .sort_index().sort_index(axis=1)\n",
    ")\n",
    "Y_df = Y_df.apply(lambda x: (x - x.mean())/x.std(), axis=0)\n",
    "Y = Y_df.to_numpy()\n",
    "\n",
    "# Build X tensor (T × n_series × n_features)\n",
    "X_list = []\n",
    "for col in feature_cols:\n",
    "    pivot = (final_data\n",
    "        .pivot_table(index='year_month', columns='GVKEY', \n",
    "                     values=col, aggfunc='mean')\n",
    "        .reindex(index=Y_df.index, columns=Y_df.columns)\n",
    "    )\n",
    "    pivot = pivot.apply(lambda x: (x - x.mean())/x.std(), axis=0)\n",
    "    X_list.append(pivot.to_numpy())\n",
    "X = np.stack(X_list, axis=2)\n",
    "\n",
    "# Shift so that X[t] predicts Y[t+1]\n",
    "X_all = np.nan_to_num(X[:-1, :, :])\n",
    "Y_all = np.nan_to_num(Y[1:, :])\n",
    "\n",
    "# Time index for the test (use first day of month)\n",
    "time_index_all = pd.to_datetime(Y_df.index[1:], format='%Y-%m')\n",
    "\n",
    "# Ensure tensorly backend\n",
    "tl.set_backend(\"pytorch\")\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4853c997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_window: X_all shape (275, 127, 38), y_all shape (275, 127)\n",
      "run_window: window_size=70, n_series=127, n_features=38\n",
      "run_window: number of test windows=83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parallel preds: 100%|██████████| 83/83 [13:38<00:00,  9.86s/it] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10541, 83]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m train_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.70\u001b[39m \u001b[38;5;241m*\u001b[39m X_all\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m engine \u001b[38;5;241m=\u001b[39m PredictionTestEngine(\n\u001b[1;32m      5\u001b[0m     X_all,\n\u001b[1;32m      6\u001b[0m     Y_all,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     train_start\u001b[38;5;241m=\u001b[39mtrain_start,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m y_pred, y_true, times, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_window\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhopls_milr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_X\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_Y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/FYP Code/model/prediction_engine.py:355\u001b[0m, in \u001b[0;36mPredictionTestEngine.run_window\u001b[0;34m(self, method, verbose, n_jobs, **method_kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m time_index_test \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_index[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_start:]\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    352\u001b[0m )\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_true_all\u001b[38;5;241m.\u001b[39mravel(), y_pred_all\u001b[38;5;241m.\u001b[39mravel())\n\u001b[1;32m    357\u001b[0m true_dir \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(y_true_all\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[0;32m~/Documents/FYP Code/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/FYP Code/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:565\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m0.825...\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[1;32m    564\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 565\u001b[0m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m )\n\u001b[1;32m    569\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    570\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m _average((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Documents/FYP Code/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/FYP Code/.venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:104\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mTo reduce redundancy when calling `_find_matching_floating_dtype`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 104\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/FYP Code/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10541, 83]"
     ]
    }
   ],
   "source": [
    "# Instantiate engine\n",
    "window_size = 70\n",
    "train_start = int(0.70 * X_all.shape[0])\n",
    "engine = PredictionTestEngine(\n",
    "    X_all,\n",
    "    Y_all,\n",
    "    window_size=window_size,\n",
    "    time_index=time_index_all,\n",
    "    train_start=train_start,\n",
    ")\n",
    "\n",
    "y_pred, y_true, times, metrics = engine.run_window(\n",
    "    method=\"hopls_milr\"\n",
    "    , R=40, Ln=(6, 6), epsilon=1e-6, verbose=True, n_jobs=7, lambda_X = 1e-4, lambda_Y = 1e-7, alpha=1.2\n",
    ")\n",
    "\n",
    "print(\"Overall metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Plot results for series 0\n",
    "engine.plot_results(series_indices=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955eebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate engine\n",
    "window_size = 80\n",
    "train_start = int(0.70 * X_all.shape[0])\n",
    "engine = PredictionTestEngine(\n",
    "    X_all,\n",
    "    Y_all,\n",
    "    window_size=window_size,\n",
    "    time_index=time_index_all,\n",
    "    train_start=train_start,\n",
    ")\n",
    "\n",
    "y_pred, y_true, times, metrics = engine.run_window(\n",
    "    method=\"hopls_milr\"\n",
    "    , R=40, Ln=(6, 6), epsilon=1e-6, verbose=True, n_jobs=7, lambda_X = 1e-4, lambda_Y = 1e-7, alpha=1.2\n",
    ")\n",
    "\n",
    "print(\"Overall metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Plot results for series 0\n",
    "engine.plot_results(series_indices=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b865ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate engine\n",
    "window_size = 60\n",
    "train_start = int(0.70 * X_all.shape[0])\n",
    "engine = PredictionTestEngine(\n",
    "    X_all,\n",
    "    Y_all,\n",
    "    window_size=window_size,\n",
    "    time_index=time_index_all,\n",
    "    train_start=train_start,\n",
    ")\n",
    "\n",
    "y_pred, y_true, times, metrics = engine.run_window(\n",
    "    method=\"hopls_milr\"\n",
    "    , R=40, Ln=(6, 6), epsilon=1e-6, verbose=True, n_jobs=7, lambda_X = 1e-4, lambda_Y = 1e-7, alpha=4\n",
    ")\n",
    "\n",
    "print(\"Overall metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Plot results for series 0\n",
    "engine.plot_results(series_indices=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate engine\n",
    "window_size = 60\n",
    "train_start = int(0.70 * X_all.shape[0])\n",
    "engine = PredictionTestEngine(\n",
    "    X_all,\n",
    "    Y_all,\n",
    "    window_size=window_size,\n",
    "    time_index=time_index_all,\n",
    "    train_start=train_start,\n",
    ")\n",
    "\n",
    "y_pred, y_true, times, metrics = engine.run_window(\n",
    "    method=\"hopls_milr\"\n",
    "    , R=50, Ln=(12, 12), epsilon=1e-7, verbose=True, n_jobs=7, lambda_X = 1e-2, lambda_Y = 1e-7, alpha=4\n",
    ")\n",
    "\n",
    "print(\"Overall metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Plot results for series 0\n",
    "engine.plot_results(series_indices=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d5e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate engine\n",
    "window_size = 60\n",
    "train_start = int(0.70 * X_all.shape[0])\n",
    "engine = PredictionTestEngine(\n",
    "    X_all,\n",
    "    Y_all,\n",
    "    window_size=window_size,\n",
    "    time_index=time_index_all,\n",
    "    train_start=train_start,\n",
    ")\n",
    "\n",
    "y_pred, y_true, times, metrics = engine.run_window(\n",
    "    method=\"hopls_milr\"\n",
    "    , R=10, Ln=(8, 8), epsilon=1e-7, verbose=True, n_jobs=7, lambda_X = 1e-2, lambda_Y = 1e-7, alpha=2\n",
    ")\n",
    "\n",
    "print(\"Overall metrics:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Plot results for series 0\n",
    "engine.plot_results(series_indices=[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
